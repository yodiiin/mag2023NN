{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "#################################### Correct your environment if needed! ##########################################\n",
    "\n",
    "# !pip3 -qq install torch==0.4.1\n",
    "# !pip3 -qq install bokeh==0.13.0\n",
    "# !pip3 -qq install gensim==3.6.0\n",
    "# !pip3 -qq install nltk\n",
    "# !pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QstS4NO0L97c",
    "outputId": "3fb123c6-640e-4538-e725-b7b0ad2790fc"
   },
   "outputs": [],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTai8Ta0lgwL",
    "outputId": "da62a113-9b4b-42da-d07b-13c6c280a31f"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCjwwDs6Zq9x",
    "outputId": "ef53325f-5745-4913-db3d-f769c08de16e"
   },
   "outputs": [],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "URC1B2nvPGFt",
    "outputId": "a61e557b-21c5-40b5-b0d2-d5894941c316"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rWmSToIaeAo",
    "outputId": "18ceba1e-2f48-435e-c7ce-24e22e9558ab"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4XsRII5kW5x",
    "outputId": "e0e8f67c-36e2-4ae4-ced9-0791fc24ed59"
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n",
    "        self._out_layer = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self._emb(inputs)\n",
    "        out, _ = self._lstm(emb)\n",
    "        return self._out_layer(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "Посчитаем accuracy и loss, а заодно проверим, что модель работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbrxsZ2mehWB",
    "outputId": "a5e9b1cf-508e-4a98-cbb2-a8c9dbbfffa1"
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "\n",
    "preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "mask = (y_batch != 0).float()\n",
    "correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
    "total_count = mask.sum().item()\n",
    "\n",
    "correct_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMUyUm1hgpe3",
    "outputId": "771a60b7-063a-4551-b92a-7ce8850ddbb5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion(logits.transpose(2, 1), y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = optimizer is not None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "                mask = (y_batch != 0).float()\n",
    "                cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
    "                cur_sum_count = mask.sum().item()\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if val_data is not None and val_batch_size is not None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if val_data is not None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "Pqfbeh1ltEYa",
    "outputId": "706de9e1-5daa-4931-a30a-ce333b8a745f"
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98wr38_rw55D",
    "outputId": "4ed5543a-922a-4eb2-c883-bdc5f62cfc71"
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "sum_count = 0\n",
    "\n",
    "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
    "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "    logits = model(X_batch)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    mask = (y_batch != 0).float()\n",
    "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
    "    cur_sum_count = mask.sum().item()\n",
    "                \n",
    "    correct_count += cur_correct_count\n",
    "    sum_count += cur_sum_count\n",
    "\n",
    "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wGIxc7dDt1A1"
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self._emb(inputs)\n",
    "        out, _ = self._lstm(emb)\n",
    "        return self._out_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "wyFL_YH342h-",
    "outputId": "6c377df3-d45d-4b02-aa75-7a073a92ab3e"
   },
   "outputs": [],
   "source": [
    "model = BidirectionalLSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5mutipY8QGZ",
    "outputId": "448c137e-3b2f-4a65-f54e-04eb8ae25ac9"
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "sum_count = 0\n",
    "\n",
    "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
    "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "    logits = model(X_batch)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    mask = (y_batch != 0).float()\n",
    "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
    "    cur_sum_count = mask.sum().item()\n",
    "                \n",
    "    correct_count += cur_correct_count\n",
    "    sum_count += cur_sum_count\n",
    "\n",
    "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZpY_Q1xZ18h",
    "outputId": "e860eb01-c37f-4161-88ae-06d555a09705"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsCstxiO03oT",
    "outputId": "8716df79-24a5-4d63-8ac9-c796c49ec4ed"
   },
   "outputs": [],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "Сделаем модель с предобученной матрицей. Будем использовать `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._emb = nn.Embedding.from_pretrained(embeddings)\n",
    "        self._lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self._emb(inputs)\n",
    "        out, _ = self._lstm(emb)\n",
    "        return self._out_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "EBtI6BDE-Fc7",
    "outputId": "da305453-3e9f-435e-8f03-fc2e5aa391a3"
   },
   "outputs": [],
   "source": [
    "model = BidirectionalLSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=torch.FloatTensor(embeddings),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPUuAPGhEGVR",
    "outputId": "4f1dc171-d964-441d-eda6-ba96975f8702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 97.06%\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "sum_count = 0\n",
    "\n",
    "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
    "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "    logits = model(X_batch)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    mask = (y_batch != 0).float()\n",
    "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
    "    cur_sum_count = mask.sum().item()\n",
    "                \n",
    "    correct_count += cur_correct_count\n",
    "    sum_count += cur_sum_count\n",
    "\n",
    "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoxlK4Zf8Ybq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
