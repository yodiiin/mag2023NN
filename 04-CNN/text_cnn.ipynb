{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyh0knhqJx8u"
   },
   "source": [
    "понятное [видео](https://www.youtube.com/watch?v=bNb2fEVKeEo) со стенфордского курса, из [материалов](https://cs231n.github.io/convolutional-networks) по которому взяты иллюстрации.\n",
    "\n",
    "Датасет из [курса](https://github.com/DanAnastasyev/DeepNLP-Course/blob/master/Week%2004/Week_04_Convolutional_Neural_Networks.ipynb) Даниила Анастасьева.\n",
    "\n",
    "Использовались [материалы](https://github.com/mannefedov/hse_ml_m1/blob/master/7_cnn/cnn.ipynb) из курса Михаила Нефедова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdbHKxg6J8Q3"
   },
   "source": [
    "# Сверточный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G20z18IaJ6Y5"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Желтое - фильтр (= filter,kernel).\n",
    "\n",
    "Зеленое - входные данные, например, изображение.\n",
    "\n",
    "Розовое - карта активации (activation map).\n",
    "\n",
    "Каждый элемент в розовой матрице - результат поэлементного умножения фильтра на числа из области на входных данных.\n",
    "Обучаемые параметры - элементы фильтра.\n",
    "\n",
    "![Conv](https://image.ibb.co/e6t8ZK/Convolution.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXNixkx2KHsm"
   },
   "source": [
    "Чтобы не терять размер матрицы используется паддинг.\n",
    "\n",
    "![padding](https://3deep.ru/wp-content/uploads/2020/01/keras_conv2d_padding.gif)\n",
    "\n",
    "from https://3deep.ru/machinelearning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp44YeUKKSem"
   },
   "source": [
    "# Pooling слой  (не обучается)\n",
    "\n",
    "![Pool](https://cs231n.github.io/assets/cnn/pool.jpeg)\n",
    "![maxpool](https://cs231n.github.io/assets/cnn/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VqCU9o5KUmr",
    "tags": []
   },
   "source": [
    "# Свертки для текстов устроены немного по-другому. В них на одну размерность меньше.\n",
    "\n",
    "![text-convs](https://image.ibb.co/bC3Xun/2018_03_27_01_24_39.png)\n",
    "\n",
    "From [Character-Aware Neural Language Models](https://arxiv.org/pdf/1508.06615.pdf)\n",
    "\n",
    "![conv-maxpool](conv_maxpooling_steps.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXx-iELMKUjt"
   },
   "source": [
    "# CNN для обработки текстов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgiT9Xow1sd5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import BinaryF1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfxNXovr1sd6"
   },
   "source": [
    "### Находим фамилии среди слов русского языка\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZtLedfF00Ih"
   },
   "source": [
    "### Скачивание и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEBb-YaTR1os",
    "outputId": "5d4e7170-3a62-4000-8b04-64e79c0179bf"
   },
   "outputs": [],
   "source": [
    "!wget -O surnames.txt  \"https://drive.google.com/uc?export=download&id=1z7avv1JiI30V4cmHJGFIfDEs9iE4SHs5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17_AP7LhLPnv"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('surnames.txt', encoding='utf-8', sep='\\t', header=None,  names=['word','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JYJtXCaERbb"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfA7yoOFA4cm",
    "outputId": "ed113ddd-a4c9-4019-cef1-a60898ecd691"
   },
   "outputs": [],
   "source": [
    "train_data[train_data.label == 1].shape[0] / train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "45ebLSllFFAW",
    "outputId": "dc094ba1-a780-4e5c-e784-3101463299b6"
   },
   "outputs": [],
   "source": [
    "train_data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-q1JHzW1sd-"
   },
   "source": [
    "Теперь нам нужно собрать все символы в словарь. Лучше сразу посчитать количество упоминаний, чтобы отсеять самые редкие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8t4nDCR1sd-",
    "outputId": "d9acca2c-31d3-463d-a2d2-6bcdc127db49"
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for symbol in data['word']:\n",
    "    vocab.update(list(symbol))\n",
    "print('всего уникальных символов:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFlVinuMObSL",
    "outputId": "fed8ab1c-c343-4b90-f432-6a27190e3cba"
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wKHM_LU1seA",
    "outputId": "22c2891d-2daa-4c43-8a7d-7b0e4f10d807"
   },
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for symbol in vocab:\n",
    "    if vocab[symbol] > 5:\n",
    "        filtered_vocab.add(symbol)\n",
    "print('уникальных символов, встретившихся больше 5 раз:', len(filtered_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEUhJv5N1seC"
   },
   "outputs": [],
   "source": [
    "#создаем словарь с индексами symbol2id, для спецсимвола паддинга дефолтный индекс - 0\n",
    "symbol2id = {'PAD': 0}\n",
    "\n",
    "for symbol in filtered_vocab:\n",
    "    symbol2id[symbol] = len(symbol2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6J89I9d1seC"
   },
   "outputs": [],
   "source": [
    "#обратный словарь для того, чтобы раскодировать последовательность\n",
    "id2symbol = {i: symbol for symbol, i in symbol2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrzM7MnCQeP_",
    "outputId": "5ecd631f-a97a-438c-b9d2-3f994eb9a806"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obiXRWLt1OZJ"
   },
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMs4ZohJ1seI"
   },
   "outputs": [],
   "source": [
    "class SurnamesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, symbol2id, DEVICE):\n",
    "        self.dataset = dataset['word'].values\n",
    "        self.symbol2id = symbol2id\n",
    "        self.length = dataset.shape[0]\n",
    "        self.target = dataset['label'].values\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        symbols = list(self.dataset[index])\n",
    "        ids = torch.LongTensor([self.symbol2id[symbol] for symbol in symbols if symbol in self.symbol2id])\n",
    "        y = [self.target[index]]\n",
    "        return ids, y\n",
    "\n",
    "    def collate_fn(self, batch): #этот метод можно реализовывать и отдельно,\n",
    "        # он понадобится для DataLoader во время итерации по батчам\n",
    "        ids, y = list(zip(*batch))\n",
    "        padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
    "        y = torch.Tensor(y).to(self.device)\n",
    "        return padded_ids, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5Wjfyxar7U1"
   },
   "source": [
    "### создаем итераторы по данным для трейна и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Zl4FxB71seI"
   },
   "outputs": [],
   "source": [
    "train_dataset = SurnamesDataset(train_data, symbol2id, DEVICE)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xauLXZwQNcCq"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOqAu8X8S36K",
    "outputId": "b0d6b0b8-b334-4bdf-8181-f0b4324d747c"
   },
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZbD27_A6Nck",
    "outputId": "14d5a1f5-6037-4976-cff2-60f24266ff5d"
   },
   "outputs": [],
   "source": [
    "[id2symbol[int(i)] for i in batch[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tj6Wltq3TfGQ",
    "outputId": "7eb93dea-f5f6-4748-b9db-70bf93b82de3"
   },
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZR_upb-_1seJ"
   },
   "outputs": [],
   "source": [
    "val_dataset = SurnamesDataset(val_data, symbol2id, DEVICE)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_iterator = DataLoader(val_dataset, collate_fn = val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQlpcUR28V-j",
    "outputId": "70c82a34-0bd9-4968-a2f6-ce2c261e8a19"
   },
   "outputs": [],
   "source": [
    "test_batch = next(iter(val_iterator))\n",
    "test_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUCT8ayD1seK"
   },
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfVEoM-IZFFe",
    "outputId": "8f421f2e-f59e-4eb1-fc81-1d45ff47da1e"
   },
   "outputs": [],
   "source": [
    "fm = torch.randn(3, 8, 4) #batch_size, num_filters, seq_len\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXXF4sU2ZFy4",
    "outputId": "84b83853-bd68-424a-db1b-71bb2f2a6862"
   },
   "outputs": [],
   "source": [
    "mp = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "print(mp(fm).shape)\n",
    "mp(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0JZy7ZDlctwM",
    "outputId": "b1696999-a3c0-4262-cb53-41bf8905754d"
   },
   "outputs": [],
   "source": [
    "fm.max(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdV7oSIc1seK"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=2, padding='same')\n",
    "        self.trigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=80, kernel_size=3, padding='same')\n",
    "        self.pooling = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden = nn.Linear(in_features=180, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, word):\n",
    "        #batch_size x seq_len\n",
    "        embedded = self.embedding(word)\n",
    "        #batch_size x seq_len x embedding_dim\n",
    "        embedded = embedded.transpose(1,2)\n",
    "        #batch_size x embedding_dim x seq_len\n",
    "        feature_map_bigrams = self.dropout(self.pooling(self.relu(self.bigrams(embedded))))\n",
    "        #batch_size x filter_count2 x seq_len* \n",
    "        feature_map_trigrams = self.dropout(self.pooling(self.relu(self.trigrams(embedded))))\n",
    "        #batch_size x filter_count3 x seq_len*\n",
    "\n",
    "        pooling1 = feature_map_bigrams.max(2)[0] \n",
    "        # batch_size x filter_count2\n",
    "        pooling2 = feature_map_trigrams.max(2)[0]\n",
    "        # batch_size x filter_count3\n",
    "        concat = torch.cat((pooling1, pooling2), 1)\n",
    "        # batch _size x (filter_count2 + filter_count3)\n",
    "        logits = self.hidden(concat) \n",
    "        logits = self.out(logits)      \n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQ-WEY4cxkv",
    "outputId": "d8a84c76-aad6-4529-a0bf-0eba0fe18e02"
   },
   "outputs": [],
   "source": [
    "batch, y = next(iter(train_iterator))\n",
    "batch, y = batch.to(device='cpu'), y.to(device='cpu')\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSmsX_fg4LcO",
    "outputId": "3fd4eec0-cf9c-4ad0-a016-d9301b1cd055"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHc9E_96dJBH",
    "outputId": "906c52ad-5e04-4586-990f-b5e9adc6edbd"
   },
   "outputs": [],
   "source": [
    "model = CNN(len(id2symbol), 8)\n",
    "output = model(batch)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBWdfROdQK5v",
    "outputId": "93408385-6f5c-45f7-e6ed-d2feafd8d6c7"
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = BinaryF1Score(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q73ELWxPzjtZ",
    "outputId": "5a18feb0-b932-407f-8a2e-02b1fa41e8b5"
   },
   "outputs": [],
   "source": [
    "f1(output, y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYz0OzYT1vt1"
   },
   "source": [
    "### training loop, логика обучения и валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8sZOK7Kvk7o"
   },
   "source": [
    "теперь нам нужны функции для обучения и валидации,\n",
    "каждый вызов функции - одна эпоха обучения \n",
    "\n",
    "За одну эпоху нам надо для каждого батча:\n",
    "\n",
    "-- применить к нему модель, \n",
    "\n",
    "-- посчитать значение функции потерь, \n",
    "\n",
    "-- посчитать градиенты,\n",
    "\n",
    "-- обновить веса (параметры модели)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVKQzPPI1seJ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0 # для подсчета среднего лосса на всех батчах\n",
    "\n",
    "    model.train()  # ставим модель в обучение, явно указываем, что сейчас надо будет хранить градиенты у всех весов\n",
    "\n",
    "    for i, (texts, ys) in enumerate(iterator): #итерируемся по батчам\n",
    "        optimizer.zero_grad()  #обнуляем градиенты\n",
    "        preds = model(texts)  #прогоняем данные через модель\n",
    "        loss = criterion(preds, ys) #считаем значение функции потерь  \n",
    "        loss.backward() #считаем градиенты  \n",
    "        optimizer.step() #обновляем веса \n",
    "        epoch_loss += loss.item() #сохраняем значение функции потерь\n",
    "        if not (i + 1) % int(len(iterator)/5):\n",
    "            print(f'Train loss: {epoch_loss/i}')      \n",
    "    return  epoch_loss / len(iterator) # возвращаем среднее значение лосса по всей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPfO7p9x1seK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (texts, ys) in enumerate(iterator):   \n",
    "            preds = model(texts)  # делаем предсказания на тесте\n",
    "            loss = criterion(preds, ys)   # считаем значения функции ошибки для статистики  \n",
    "            epoch_loss += loss.item()\n",
    "            batch_metric = f1(preds.round().long(), ys.long())\n",
    "            epoch_metric += batch_metric\n",
    "\n",
    "            if not (i + 1) % int(len(iterator)/5):\n",
    "              print(f'Val loss: {epoch_loss/i}, Val f1: {epoch_metric/i}')\n",
    "        \n",
    "    return epoch_metric / len(iterator), epoch_loss / len(iterator) # возвращаем среднее значение по всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRoSupMNQsvF"
   },
   "source": [
    "### инициализируем модель, задаем оптимизатор и функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WO35IZES1seL"
   },
   "outputs": [],
   "source": [
    "model = CNN(len(symbol2id), 8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.BCELoss()  \n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kHbVX0y1seL"
   },
   "source": [
    "### запуск обучения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boMAjlVM1seM",
    "outputId": "d2925b1a-08cc-447a-fa61-0199f7575432"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train,_ = evaluate(model, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "eH7ws8dXmEn5",
    "outputId": "3e742ebc-e57f-4d67-eb70-36240964a9d0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "q32B6i6BmGOc",
    "outputId": "9c885f61-e361-4622-d564-001b386fbcbb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(f1s)\n",
    "plt.plot(f1s_eval)\n",
    "plt.title('f1 value')\n",
    "plt.ylabel('f1 value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj0-XaCkYz8w"
   },
   "source": [
    "Для анализа ошибок можно посмотреть на те примеры, которые мы (не)правильно предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHtAIt5eCrP5"
   },
   "outputs": [],
   "source": [
    "def predict(model, iterator):\n",
    "    model.eval()\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tp = [] \n",
    "    tn = []\n",
    "    with torch.no_grad():\n",
    "        for i, (texts, ys) in enumerate(iterator):   \n",
    "            preds = model(texts)  # делаем предсказания на тесте \n",
    "            for pred, gold, text in zip(preds, ys, texts):\n",
    "              text = ''.join([id2symbol[int(symbol)] for symbol in text if symbol !=0])\n",
    "              if round(pred.item()) > gold:\n",
    "                fp.append(text)\n",
    "              elif round(pred.item()) < gold:\n",
    "                fn.append(text)\n",
    "              elif round(pred.item()) == gold == 1:\n",
    "                tp.append(text)\n",
    "              elif round(pred.item()) == gold == 0:\n",
    "                tn.append(text)\n",
    "    return fp, fn, tp, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phc1BAE4MKhU"
   },
   "outputs": [],
   "source": [
    "fp, fn, tp, tn = predict(model, val_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFiLocEC6dUa",
    "outputId": "1f9c6572-ae90-4cbb-e767-b1485882fa2e"
   },
   "outputs": [],
   "source": [
    "print('что правильно предсказываем:', tp[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeBGHMjm4LBJ",
    "outputId": "455b8bda-35c1-4d09-b4f7-117091e7a1b2"
   },
   "outputs": [],
   "source": [
    "print('ошибочно не относим к фамилиям:', fn[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztrjLRu34e-B",
    "outputId": "8f86977e-ff06-4552-a023-ab55c98974b1"
   },
   "outputs": [],
   "source": [
    "print('ошибочно считаем фамилиями:', fp[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZL6OlYcbE9d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9_CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
