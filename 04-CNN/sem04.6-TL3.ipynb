{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3206,
     "status": "ok",
     "timestamp": 1698594288056,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "LGB-rJkbQEZ7"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zuAlKtqQEZ8"
   },
   "source": [
    "# Transfer learning\n",
    "\n",
    "На этом семинаре мы научимся очень быстро обучать нейросеть на сложную задачу классификации изображений, используя очень простой приём, именуемый fine tuning'ом.\n",
    "\n",
    "Для начала скачем датасет. На этот раз мы научим нейронку отличать кошечек от собачек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12494,
     "status": "ok",
     "timestamp": 1698594507884,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "2jNqmVORQEZ9",
    "outputId": "f59473a4-3f3b-408d-ae29-2e58716e9724"
   },
   "outputs": [],
   "source": [
    "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
    "!unzip -qq kagglecatsanddogs_5340.zip\n",
    "!rm -rf PetImages/Cat/666.jpg PetImages/Dog/11702.jpg readme\\[1\\].txt CDLA-Permissive-2.0.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0bVe6foQEZ9"
   },
   "source": [
    "Удалим несколько битых изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8pZww-rQEZ-"
   },
   "source": [
    "Датасет разделим средствами pytorch'a на трейн и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1698594512775,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "Am9UgGUwQEZ_"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    \"./PetImages\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            Resize((224, 224)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5, 0.5, 0.5), (1, 1, 1)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KImCi0emQEZ_"
   },
   "source": [
    "Сделаем из скачанных датасетов даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1698594515902,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "uljsqCQXQEaA"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Z3mwchQEaA"
   },
   "source": [
    "Посмотрим, как выглядят картинки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1698594520048,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "O45fIlNuQEaA",
    "outputId": "f2ca680b-4b3b-4b4b-ab44-b4ed05f537f7"
   },
   "outputs": [],
   "source": [
    "file = np.random.choice(glob.glob(\"./PetImages/*/*.jpg\"))\n",
    "plt.imshow(plt.imread(file));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItwVf1FIQEaB"
   },
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihpGfLjqQEaC"
   },
   "source": [
    "Кошки и собаки это конечно хорошо, вот только обучение модели, которая будет хорошо работать на этом датасете может оказаться очень долгим...\n",
    "\n",
    "Однако картинки, которые мы сегодня рассмотрим оказываются очень похожими на картинки из огромного датасета ImageNet. Задача, которую мы сегодня рассмотрим, называется Transfer Learning -- в русскоязычной литературе иногда можно встретить термин \"обучение с переносом знаний\". Знания мы действительно переносим -- от сети, которая хорошо работает на одном датасете (ImageNet) к другим данным (к датасету Cats vs Dogs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfNvcOXgQEaC"
   },
   "source": [
    "### Загрузим уже обученную сеть\n",
    "\n",
    "В библиотеке `torchvision` имплементировано не только большое множество моделей (всевозможные ResNet'ы, Inception, VGG, AlexNet, DenseNet, ResNext, WideResNet, MobileNet...), но и загружены чекпоинты обучения этих моделей на ImageNet. Однако для датасета Cats vs Dogs такая штука является роскошью..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1698594529448,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "vxMgp8NeQEaC",
    "outputId": "4a20d650-1193-4480-8f57-c81f754a9d4a"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "# Загрузить предобученную сеть -- pretrained=True\n",
    "model = resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1698594533921,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "hIf1fdf-QEaD"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kapc805MQEaD"
   },
   "source": [
    "В задаче transfer learning'a мы заменяем последний слой нейросети на линейный с двумя выходами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1698594536304,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "wjs32xa5QEaD"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMzg8uKfQEaD"
   },
   "source": [
    "Ниже несколько функций, которые мы уже видели в предыдущих семинарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1698594538641,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "V3JuPsJRQEaD"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    return_losses=False,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model = model.to(device).train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    total_predictions = np.array([])  # .reshape((0, ))\n",
    "    total_labels = np.array([])  # .reshape((0, ))\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            # Move Batch to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Update descirption for tqdm\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(\n",
    "                total_predictions, predicted.argmax(1).cpu().detach().numpy()\n",
    "            )\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device=\"cuda:0\"):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    total_predictions = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(\n",
    "                total_predictions, predicted.argmax(1).cpu().detach().numpy()\n",
    "            )\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1698594542160,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "5AqpAGyFQEaE"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data_loader,\n",
    "    validation_data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    all_train_losses = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # Train step\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        train_metrics, one_epoch_train_losses = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_data_loader,\n",
    "            optimizer=optimizer,\n",
    "            return_losses=True,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "        )\n",
    "        # Save Train losses\n",
    "        all_train_losses.extend(one_epoch_train_losses)\n",
    "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
    "        # Eval step\n",
    "        print(f\"Validation Epoch: {epoch}\")\n",
    "        with torch.no_grad():\n",
    "            validation_metrics = validate(\n",
    "                model=model, data_loader=validation_data_loader, criterion=criterion\n",
    "            )\n",
    "        # Save eval losses\n",
    "        epoch_eval_losses.append(validation_metrics[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY-5mzZTQEaE"
   },
   "source": [
    "Создайте объект лосса и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1698594544466,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "p5Oh5Y8hQEaE"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), 1e-4)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjf2g663QEaE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(model, 5, train_dataloader, test_dataloader, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPk6WiNrQEaE"
   },
   "source": [
    "Как видим на одну эпоху обучения уходит порядка двух минут, и уже после одной эпохи получается приемлемое качество. Давайте проинициализируем модель с нуля и попробуем обучить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRjGr6SPQEaF"
   },
   "outputs": [],
   "source": [
    "model_full = resnet18(pretrained=False)\n",
    "model_full.fc = nn.Linear(512, 2)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), 1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507,
     "referenced_widgets": [
      "60f34732eafd46bfa46ac7e2ae1e66f4",
      "ab4798cc406b4482acd3d8cce87b6ff6",
      "d3668b025b4840e18f4932fbdb822ecf",
      "1383bf7d4088416784352ed4a52eb6f9",
      "944b2939c8d54fa9b6eb70e129e26e30",
      "f3e7a57d130c43fb849947125fd11431",
      "5fec86b06e7f4212b0351554c463fb2a",
      "7e4fd9511c50410bafae7eb13462a01c",
      "42667fe886504dbdb1bc4ba2858de5f4",
      "c999d2ae87a540169625e48721fd777f",
      "8f8035f76e614211a270fea61367a11a",
      "a76d05656b7a45cea4ec2108b7e2a113",
      "29e4684115a34127aa38b4b3cd095a3d",
      "d1d3e8391dca42549e79229c1ed6d2f7",
      "046b1bd279fa421c8cc04d02d04574bb",
      "52c24dbc04b04e828b71b571b00b7d43",
      "24972972a7b4495eb4e439415e9f7379",
      "e87b82f7979948278f02cf57ae7d9d2f",
      "ec170692301f4e619f0612df5a7fc7cb",
      "078644374b3249149b8b3bfeb8a7d86e"
     ]
    },
    "id": "0Fr3dCIZQEaF",
    "outputId": "958edc72-1fb5-49f5-fb1e-ac2b975f276c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(\n",
    "    model_full,\n",
    "    5,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xr5TLEA2QEaF"
   },
   "source": [
    "__Вопрос__. Почему при обучении полной модели получается так, что время на одну эпоху почти такое же?\n",
    "\n",
    "Рекомендуем подумать на этим вопросом самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7sQEUbPQEaF"
   },
   "source": [
    "Как мы видим, на transfer learning'e нейросеть сходится очень быстро. Значительно быстрее, чем инициализированная с нуля. Можно с уверенностью говорить, что transfer learning -- очень полезная техника."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp2tWTkuQEaF"
   },
   "source": [
    "## Adversarial атаки.\n",
    "\n",
    "Такая вещь, как атаки на нейросеть крайне важны для учёта при разработке. Существует много методов как их генерации, так и защиты от них. Мы рассмотрим сегодня базовые концепты, чтобы дать понимание происходящего.\n",
    "\n",
    "Можем назвать adversarial атакой генерацию такого примера, который не отличим глазом от настоящего, но нейросеть будет ОЧЕНЬ уверена в том, что этот пример из другого класса. Сейчас мы попробуем сгенерировать такую собачку, что нейросеть будет уверена, что это котик.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/fgsm_panda_image.png\">\n",
    "\n",
    "Сегодня мы рассмотрим пример Fast Gradient Sign Attack (FGSM, почему там буква M в конце -- чёрт его знает...). Идея очень простая. Оказывается, что если мы через обученную нейросеть посчитаем градиент по исходной картинке, посчитаем  его знак и прибавим, умножив на маленькое число, модель подумает, что это картинка другого класса.\n",
    "\n",
    "Для того, чтобы нам посчитать градиент по входу, нам предстоит \"разморозить\" все её граиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QQPWN1uQEaF"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pV6xXVToQEaF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    pertrubated_image = image + epsilon * torch.sign(data_grad)\n",
    "    return pertrubated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgftrRH-QEaG"
   },
   "source": [
    "Выбираем из датасета случайную картинку с кошечкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "UW0noUhyQEaG",
    "outputId": "ec9312b6-22b5-468d-8e33-a802a4239768"
   },
   "outputs": [],
   "source": [
    "cl = 1\n",
    "while cl == 1:\n",
    "    i = np.random.randint(0, len(train_set))\n",
    "    cl = train_set[i][1]\n",
    "    image = train_set[i][0]\n",
    "    image = image.to(device)\n",
    "    # Разрешим вычисление градиента по картинке\n",
    "    image.requires_grad = True\n",
    "\n",
    "    pred = model(image[None])\n",
    "    predicted_label = pred.argmax(1).item()\n",
    "    confidence = pred.softmax(1)[0][predicted_label]\n",
    "\n",
    "\n",
    "# красиво рисуем\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item())\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item())\n",
    "plt.imshow(image.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PMx0d1rQEaG"
   },
   "source": [
    "Самое интересное начинается тут. Вычислим градиент функции потерь по картинке при помощи вызова .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2kJGHZMQEaG"
   },
   "outputs": [],
   "source": [
    "loss = criterion(pred, torch.tensor(cl).reshape((1,)).to(device))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rXEUZ7lQEaG"
   },
   "source": [
    "Произведём атаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "Rr7rZicHQEaG",
    "outputId": "103bb883-a555-4307-f50c-d48e33ab7d52"
   },
   "outputs": [],
   "source": [
    "eps = 0.007\n",
    "\n",
    "attack = fgsm_attack(image, eps, image.grad)\n",
    "pred = model(attack[None])\n",
    "predicted_label = pred.argmax(1).item()\n",
    "confidence = pred.softmax(1)[0][predicted_label]\n",
    "\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item())\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item())\n",
    "plt.imshow(attack.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB7iGLpPQLL8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1383bf7d4088416784352ed4a52eb6f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42667fe886504dbdb1bc4ba2858de5f4",
      "max": 79,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e4fd9511c50410bafae7eb13462a01c",
      "value": 79
     }
    },
    "42667fe886504dbdb1bc4ba2858de5f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fec86b06e7f4212b0351554c463fb2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60f34732eafd46bfa46ac7e2ae1e66f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3668b025b4840e18f4932fbdb822ecf",
       "IPY_MODEL_1383bf7d4088416784352ed4a52eb6f9",
       "IPY_MODEL_944b2939c8d54fa9b6eb70e129e26e30"
      ],
      "layout": "IPY_MODEL_ab4798cc406b4482acd3d8cce87b6ff6"
     }
    },
    "7e4fd9511c50410bafae7eb13462a01c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f8035f76e614211a270fea61367a11a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "944b2939c8d54fa9b6eb70e129e26e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f8035f76e614211a270fea61367a11a",
      "placeholder": "​",
      "style": "IPY_MODEL_c999d2ae87a540169625e48721fd777f",
      "value": " 79/79 [03:55&lt;00:00,  2.23s/it]"
     }
    },
    "ab4798cc406b4482acd3d8cce87b6ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c999d2ae87a540169625e48721fd777f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3668b025b4840e18f4932fbdb822ecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fec86b06e7f4212b0351554c463fb2a",
      "placeholder": "​",
      "style": "IPY_MODEL_f3e7a57d130c43fb849947125fd11431",
      "value": "Loss: 0.6696 Accuracy: 63.3333: 100%"
     }
    },
    "f3e7a57d130c43fb849947125fd11431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
