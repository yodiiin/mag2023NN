{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jA4Uhu1WkPqR"
   },
   "source": [
    "Установим torchmetrics, чтобы руками не считать точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9eh4gJ-jVtk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torchvision torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6062,
     "status": "ok",
     "timestamp": 1697964223757,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "2kXlTQG2i6P1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from torchmetrics import Accuracy as VAccuracy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cклонируем с гитхаба датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgTq5Z78jHpg"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/fortvivlan/catset.git\n",
    "# %cd catset if run locally \n",
    "%cd content/catset\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At-hqwdfnF0p"
   },
   "source": [
    "Напишем функцию, которая будет сплитить наш датасет: сперва отшаффлим индексы и разделим их стандартной ск-лерновской тулзой, а потом воспользуемся утилитой торча Subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder('Cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем датасет на:\n",
    "1. Трейн (70%) - на чем модель будет учиться;\n",
    "2. Валидацию (15%) - на чем мы будем оценивать гиперпараметры модели и выбирать наилучшую модель;\n",
    "3. Тест (15%) - для оценки качества наилучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1697964236815,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "4L1SYvDGi6P3"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.70, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо подготовить датасет к работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-превых, картинки в батче нужно превратить в тензоры, потому что нейросеть работает с тензорами. Благо, нам мне нужно итерироваться по датасету, загружать все свои тяжелые картинки в оперативную память и ручками кастовать их к тензорам - торч умеет делать это за нас, причём гораздо эффективнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1697964227934,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "3n-iiipWi6P2"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dummy_dataset = datasets.ImageFolder('Cats', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIgJ3iaxi6P2"
   },
   "source": [
    "Во-вторых, картинки неплохо бы нормализовать: помним, что любая картинка эссеншали только матрица с чиселками. Сделаем наши картинки не слишком яркими, чтобы все они были примерно одинаковыми по интенсивности цвета и подобное. Для этого нужно предпосчитать среднее и стандартное отклонение по датасету.\n",
    "\n",
    "**Важно:** среднее и дисперсию оцениваем только на основе трейна и валидации, т.к. это тоже своего рода гиперпараметры, которые ни в коем случае не должны знать про тестовую выборку! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1697964226356,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "wIC8EPj_i6P2"
   },
   "outputs": [],
   "source": [
    "def estimate_mean_std(dataset) -> tuple[float]:\n",
    "    '''Calculate channelwise mean and std for dataset'''\n",
    "        \n",
    "    channels_sum, channels_squared_sum, num_pixels = 0, 0, 0\n",
    "    for sample, _ in dataset: # sample - картинка, _ - класс картинки\n",
    "        sample = transforms.ToTensor()(sample)\n",
    "        # channels_sum - сумма пикселей по каждому каналу (всего три канала)\n",
    "        channels_sum += torch.sum(sample, dim=[1, 2]) # [3 x height x width]\n",
    "        channels_squared_sum += torch.sum(sample ** 2, dim=[1, 2])\n",
    "        # число пикселей в картинке\n",
    "        num_pixels += sample.size(1) * sample.size(2)\n",
    "\n",
    "    mean = channels_sum / num_pixels\n",
    "\n",
    "    std = (channels_squared_sum / num_pixels - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1697964230211,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "1u2xAd7Hi6P2",
    "outputId": "9a0d2838-cebf-4f72-f0ce-c30826fb449a"
   },
   "outputs": [],
   "source": [
    "mean, std = estimate_mean_std(train_dataset)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwT6yH4Hi6P2"
   },
   "source": [
    "Получили нужные чиселки: теперь нужно добавить их в трансформацию, которую будем использовать уже в реальной подготовке датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1697964232521,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "z1njG_Mji6P2"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "dataset = datasets.ImageFolder('Cats', transform=transform)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.70, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1697964237927,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "Lmi9Hq03i6P3"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXDdtkeoi6P3"
   },
   "source": [
    "Ну вот, теперь поставка данных готова, пора писать трейнлуп и архитектурку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1697964240243,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "qVIFviE1i6P3"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, n_epochs=5):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # train\n",
    "        for x_train, y_train in tqdm(train_dataloader):\n",
    "            y_pred = model(x_train)\n",
    "            loss = F.cross_entropy(y_pred, y_train) # используем кросс-энтропию\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # validation\n",
    "        if epoch % 2 == 0:\n",
    "            val_loss = []\n",
    "            val_accuracy = []\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in tqdm(val_dataloader):\n",
    "                    y_pred = model(x_val)\n",
    "                    loss = F.cross_entropy(y_pred, y_val)\n",
    "                    val_loss.append(loss.numpy())\n",
    "                    val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "\n",
    "            print(f\"Epoch: {epoch}\\tloss: {np.mean(val_loss)}\\taccuracy: {np.mean(val_accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1697964242502,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "skVIbrFFi6P3"
   },
   "outputs": [],
   "source": [
    "class Torchic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # VGG\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) # 3 канала, 10 ядер, размер ядра - 5\n",
    "        # картинка сожмется на x - (kernel_size - 1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        # картинка сожмется на x - (kernel_size - 1)\n",
    "        self.pool = nn.MaxPool2d(2) # макс-пулинг: уменьшим на 2\n",
    "        # картинка сожмется в два раза\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # head\n",
    "        # исходные картинки были 256х256х3. После первого слоя сверток стало: 252х252х10)\n",
    "        # после второго слоя сверток стало: 248х248х20\n",
    "        # после пулинга стало 124х124х20\n",
    "        self.fc1 = nn.Linear(124 * 124 * 20, 128) # слой на 128 нейронов\n",
    "        self.fc2 = nn.Linear(128, 2) # выходной слой на 2 нейрона (можно было 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1697964244822,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "vyyjtNhNi6P3"
   },
   "outputs": [],
   "source": [
    "set_random_seed(123)\n",
    "torchic = Torchic()\n",
    "optimizer = opt.Adam(torchic.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWgPC1L-i6P3"
   },
   "outputs": [],
   "source": [
    "train(torchic, optimizer, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1697964346851,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "03566560446750535462"
     },
     "user_tz": -180
    },
    "id": "u0PEY_Kii6P4"
   },
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    \"\"\"A function for plotting unnormalized images, but it still gets clipping warning\"\"\"\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img * std + mean\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (0, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZILGAIbmi6P4"
   },
   "outputs": [],
   "source": [
    "classes = {0: 'Лисена', 1: 'Мороша'}\n",
    "\n",
    "torchic.eval()\n",
    "for i in range(10):\n",
    "    img, label = test_dataset[i]\n",
    "    # нам здесь приходится перевернуть, чтобы обратно разнормализовать нашу картинку\n",
    "    matplotlib_imshow(img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    print(f\"Dat is {classes[label]}\")\n",
    "    ypred = torchic(img.unsqueeze(0))\n",
    "    print(f\"Torchic thinks it is {classes[torch.argmax(ypred, dim=-1).item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/fortvivlan/catset/blob/main/cats.ipynb",
     "timestamp": 1697964099189
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
